{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(original_dataset_dir, base_dir):\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    validation_dir = os.path.join(base_dir, 'validation')\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "    train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "    os.makedirs(train_cats_dir, exist_ok=True)\n",
    "    train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "    os.makedirs(train_dogs_dir, exist_ok=True)\n",
    "\n",
    "    validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "    os.makedirs(validation_cats_dir, exist_ok=True)\n",
    "    validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "    os.makedirs(validation_dogs_dir, exist_ok=True)\n",
    "\n",
    "    cat_fnames = [fname for fname in os.listdir(original_dataset_dir) if fname.startswith('cat')]\n",
    "    dog_fnames = [fname for fname in os.listdir(original_dataset_dir) if fname.startswith('dog')]\n",
    "\n",
    "    train_cats, validation_cats = train_test_split(cat_fnames, test_size=0.2,train_size=0.8,random_state=42)\n",
    "    train_dogs, validation_dogs = train_test_split(dog_fnames, test_size=0.2,train_size=0.8,random_state=42)\n",
    "\n",
    "    for fname in train_cats:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(train_cats_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for fname in validation_cats:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(validation_cats_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for fname in train_dogs:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(train_dogs_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for fname in validation_dogs:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(validation_dogs_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    return train_dir, validation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dir, validation_dir):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(model, image_path):\n",
    "    test_image = load_img(image_path, target_size=(64, 64))\n",
    "    test_image = img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = model.predict(test_image)\n",
    "\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 'dog'\n",
    "    else:\n",
    "        prediction = 'cat'\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "625/625 [==============================] - 261s 415ms/step - loss: 0.6196 - accuracy: 0.6518 - val_loss: 0.5629 - val_accuracy: 0.6980\n",
      "Epoch 2/25\n",
      "625/625 [==============================] - 105s 167ms/step - loss: 0.5371 - accuracy: 0.7332 - val_loss: 0.5425 - val_accuracy: 0.7324\n",
      "Epoch 3/25\n",
      "625/625 [==============================] - 103s 164ms/step - loss: 0.4987 - accuracy: 0.7511 - val_loss: 0.4564 - val_accuracy: 0.7804\n",
      "Epoch 4/25\n",
      "625/625 [==============================] - 109s 174ms/step - loss: 0.4670 - accuracy: 0.7742 - val_loss: 0.5007 - val_accuracy: 0.7546\n",
      "Epoch 5/25\n",
      "625/625 [==============================] - 103s 165ms/step - loss: 0.4455 - accuracy: 0.7888 - val_loss: 0.4789 - val_accuracy: 0.7798\n",
      "Epoch 6/25\n",
      "625/625 [==============================] - 100s 160ms/step - loss: 0.4279 - accuracy: 0.7991 - val_loss: 0.4200 - val_accuracy: 0.8018\n",
      "Epoch 7/25\n",
      "625/625 [==============================] - 109s 175ms/step - loss: 0.4103 - accuracy: 0.8134 - val_loss: 0.4459 - val_accuracy: 0.7916\n",
      "Epoch 8/25\n",
      "625/625 [==============================] - 103s 164ms/step - loss: 0.3941 - accuracy: 0.8205 - val_loss: 0.4016 - val_accuracy: 0.8212\n",
      "Epoch 9/25\n",
      "625/625 [==============================] - 102s 163ms/step - loss: 0.3840 - accuracy: 0.8265 - val_loss: 0.4361 - val_accuracy: 0.7994\n",
      "Epoch 10/25\n",
      "625/625 [==============================] - 104s 166ms/step - loss: 0.3670 - accuracy: 0.8325 - val_loss: 0.4621 - val_accuracy: 0.7916\n",
      "Epoch 11/25\n",
      "625/625 [==============================] - 103s 164ms/step - loss: 0.3519 - accuracy: 0.8428 - val_loss: 0.4178 - val_accuracy: 0.8166\n",
      "Epoch 12/25\n",
      "625/625 [==============================] - 100s 160ms/step - loss: 0.3454 - accuracy: 0.8467 - val_loss: 0.4055 - val_accuracy: 0.8196\n",
      "Epoch 13/25\n",
      "625/625 [==============================] - 105s 168ms/step - loss: 0.3257 - accuracy: 0.8565 - val_loss: 0.4296 - val_accuracy: 0.8094\n",
      "Epoch 14/25\n",
      "625/625 [==============================] - 101s 162ms/step - loss: 0.3110 - accuracy: 0.8640 - val_loss: 0.4151 - val_accuracy: 0.8192\n",
      "Epoch 15/25\n",
      "625/625 [==============================] - 99s 158ms/step - loss: 0.3014 - accuracy: 0.8690 - val_loss: 0.4191 - val_accuracy: 0.8174\n",
      "Epoch 16/25\n",
      "625/625 [==============================] - 94s 151ms/step - loss: 0.2915 - accuracy: 0.8732 - val_loss: 0.3984 - val_accuracy: 0.8316\n",
      "Epoch 17/25\n",
      "625/625 [==============================] - 109s 175ms/step - loss: 0.2729 - accuracy: 0.8855 - val_loss: 0.4278 - val_accuracy: 0.8254\n",
      "Epoch 18/25\n",
      "625/625 [==============================] - 108s 173ms/step - loss: 0.2693 - accuracy: 0.8864 - val_loss: 0.4375 - val_accuracy: 0.8152\n",
      "Epoch 19/25\n",
      "625/625 [==============================] - 113s 181ms/step - loss: 0.2570 - accuracy: 0.8921 - val_loss: 0.4387 - val_accuracy: 0.8198\n",
      "Epoch 20/25\n",
      "625/625 [==============================] - 110s 175ms/step - loss: 0.2455 - accuracy: 0.8964 - val_loss: 0.4253 - val_accuracy: 0.8298\n",
      "Epoch 21/25\n",
      "625/625 [==============================] - 105s 168ms/step - loss: 0.2397 - accuracy: 0.8978 - val_loss: 0.5342 - val_accuracy: 0.7986\n",
      "Epoch 22/25\n",
      "625/625 [==============================] - 104s 167ms/step - loss: 0.2256 - accuracy: 0.9058 - val_loss: 0.4418 - val_accuracy: 0.8354\n",
      "Epoch 23/25\n",
      "625/625 [==============================] - 103s 165ms/step - loss: 0.2203 - accuracy: 0.9089 - val_loss: 0.4496 - val_accuracy: 0.8262\n",
      "Epoch 24/25\n",
      "625/625 [==============================] - 115s 184ms/step - loss: 0.2045 - accuracy: 0.9165 - val_loss: 0.4641 - val_accuracy: 0.8344\n",
      "Epoch 25/25\n",
      "625/625 [==============================] - 109s 174ms/step - loss: 0.2045 - accuracy: 0.9144 - val_loss: 0.5006 - val_accuracy: 0.8270\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    original_dataset_dir = 'train/train'\n",
    "    base_dir = 'train/train'\n",
    "    train_dir, validation_dir = prepare_data(original_dataset_dir, base_dir)\n",
    "    model = define_model()\n",
    "    train_model(model, train_dir, validation_dir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n",
      "157/157 [==============================] - 11s 65ms/step\n",
      "Confusion Matrix:\n",
      "[[1945  555]\n",
      " [ 310 2190]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.86      0.78      0.82      2500\n",
      "         dog       0.80      0.88      0.84      2500\n",
      "\n",
      "    accuracy                           0.83      5000\n",
      "   macro avg       0.83      0.83      0.83      5000\n",
      "weighted avg       0.83      0.83      0.83      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "def evaluate_model(model, validation_dir):\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)  \n",
    "    true_labels = validation_generator.classes\n",
    "\n",
    "    predictions = model.predict(validation_generator, steps=len(validation_generator))\n",
    "    predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    class_report = classification_report(true_labels, predicted_labels, target_names=[\"cat\", \"dog\"])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "evaluate_model(model, validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n",
      "The image is of a dog\n"
     ]
    }
   ],
   "source": [
    "image_path = 'test1/test1/12471.jpg'\n",
    "print(f\"The image is of a {classify_image(model, image_path)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
